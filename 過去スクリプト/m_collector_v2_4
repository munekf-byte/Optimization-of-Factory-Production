import asyncio
from playwright.async_api import async_playwright
import gspread
from oauth2client.service_account import ServiceAccountCredentials
import re

# --- 司令塔：つくば店で成功した時の設定に近い形に ---
TARGET_STORES = [
    {
        "name": "学園の森", # 成功時と同じく、サイトで見える名前を信じる
        "sheet_id": "1koHCi0l4KcsuMBEYSYRx_lklniibQHeCYaO_k-GUU1I"
    }
]
# ----------------------------

async def main():
    scope = ['https://spreadsheets.google.com/feeds', 'https://www.googleapis.com/auth/drive']
    creds = ServiceAccountCredentials.from_json_keyfile_name('credentials.json', scope)
    gc = gspread.authorize(creds)

    async with async_playwright() as p:
        print("専用Chromeに接続中...")
        try:
            browser = await p.chromium.connect_over_cdp("http://localhost:9222")
            context = browser.contexts[0]
            # 現在のタブを特定
            page = next((p_obj for p_obj in context.pages if "min-repo.com" in p_obj.url), None)
            if not page:
                print("みんレポのタブが見つかりません。"); return
        except Exception as e:
            print(f"接続エラー: {e}"); return

        for store in TARGET_STORES:
            print(f"=== {store['name']} 攻略開始 ===")
            try:
                sheet = gc.open_by_key(store['sheet_id'])
                raw_sheet = sheet.worksheet("生データ")
                cal_sheet = sheet.worksheet("カレンダー")
                
                # 1. リンクの「どん欲な」取得
                print("画面上のリンクをすべてスキャンしています...")
                all_links = await page.evaluate('''() => {
                    return Array.from(document.querySelectorAll('a')).map(a => ({
                        title: a.innerText.trim(),
                        href: a.href
                    }));
                }''')
                
                # 2. 成功時と同じ「店名が含まれるか」のフィルター
                valid_tasks = []
                for l in all_links:
                    if store['name'] in l['title']:
                        valid_tasks.append(l)
                
                print(f"発見数: {len(all_links)}件中、店名一致は {len(valid_tasks)}件")
                
                # 3. 取得したリンクがあれば、一つずつ開いて抜く（成功時の基本ループ）
                for task in valid_tasks:
                    print(f"  [巡回] {task['title']} を解析中...")
                    await page.goto(task['href'] + "?kishu=all", wait_until="load")
                    await page.wait_for_timeout(5000)
                    
                    # 以降、データ抽出ロジック（成功時から変えていない部分）
                    day_data = await page.evaluate('''() => {
                        const res = [];
                        document.querySelectorAll('table tr').forEach(row => {
                            const cols = row.querySelectorAll('td');
                            if (cols.length >= 5) {
                                res.push({ name: cols[0].innerText, num: cols[1].innerText, diff: cols[2].innerText, games: cols[3].innerText });
                            }
                        });
                        return res;
                    }''')
                    
                    # (ここでシートへの書き込み処理)
                    # ...（成功時と同じ処理を続行）
                    print(f"    -> {len(day_data)}件のデータを取得しました。")

            except Exception as e:
                print(f"エラー: {e}")

if __name__ == "__main__":
    asyncio.run(main())